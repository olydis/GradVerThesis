% IDEA: separate theoretical/general approach and concrete decisions
% this means, for example, that:
% PART1:
% - requirements for lifted functions, soundness
% - implication (gradual, ...)
% - abstract versions of [w/o], append
% PART2:
% - concrete version of [w/o], append, ... (probably requires notion of normalized env :( )
% - actual implementation

\chapter{Introduction}
Most modern programming languages use static analysis to some degree, ruling out certain types of runtime failure.
Static analysis provides guarantees about the dynamic behavior of a program without actually running the program.
%% static typing
Static typing disciplines are among the most common representatives of static analysis, guaranteeing type safety at compile time, obviating the need for dynamic checks.

%% static verification
Another powerful technique is static verification of programs against their specification, i.e. statically proving their “correctness”.
In practice this is achieved by checking that some annotated invariants or assertions (reflecting the specification) must always hold.
% example?
Unfortunately, static verification has limitations and drawbacks:
\begin{itemize} % TODO
    \item Syntax
    \item Decidability
    \item Difficult and Tedious to annotate programs
    \item ...
\end{itemize}
These limitations not only affect programmers trying to statically verify their program.
Most general purpose programming languages (C/C++, C\#, Java, ...), usually driven by cost-benefit and usability considerations, haven't adopted this level of static analysis in the first place.

%% grad verification
The purpose of gradual verification is to weaken if not remove some of these limitations at the cost of turning some static checks into runtime checks, whenever inevitable.
We will present a procedure of turning a static verification into a gradual one.
% more detail about static limitations and how runtime circumvents them?

%% static typing weakened
This idea is not new at all and actually common practice in type systems:
In C\# or Java, explicit type casts are assertions about the actual type of a value.
This actual type (usually a subtype of the statically known type) could not be deduced by the static type system due to its limitations.
Such an assertion/cast allows subsequent static reasoning about the value assuming its new type at the cost of an additional runtime check, ensuring the validity of the cast.
Note that such deviations from a “purely” static type system (one where there is no need for runtime checks) do not affect type safety:
It is still guaranteed that execution does not enter an invalid state (one where runtime types are incompatible with statically annotated types) by simply interrupting execution whenever a runtime type check fails.
This is usually implemented by throwing an exception.
% mention that runtime cost reasonable, ...


%% dyn typing
At the other end of the spectrum are dynamically typed languages.
In scenarios where the limitations of a static type system would clutter up the source code, they allow expressing the same logic with less syntactic overhead, but at the cost of less static guarantees and early bug detection.

%% PLs are on the dynamic end of the verification spectrum
In terms of program verification, most general purpose languages are on the dynamic end of the spectrum.
If they exist as designated syntax, assertions are usually implemented as runtime checks and often even dropped entirely for “release” builds (the Java compiler drops them by default).
It is common practice to implement 
% research Eiffel!
% Design-by-Contract!!! Eiffel!
% D even has both

% this is more of a consequence of the “deep roots” of dynamic verification!!!
%But even preconditions at expression level are implemented as runtime checks, reflected all the way down at instruction architecture level.
%Examples:
%\begin{description}
%    \item[Division by zero]~\\
%    Integer division performs a dynamic check...
%    
%\end{description}

%% grad typing
A gradual type system is more flexible, as it provides the full continuum between static and dynamic typing, letting the programmer decide ... %TODO.
It can be seen as an extension  “unknown” type 


This work will also show that gradual verification ... other angle!

- 
What is the thesis about?
Why is it relevant or important?
What are the issues or problems?
What is the proposed solution or approach?
What can one expect in the rest of the thesis?

“Static verification checks that properties are always true, but it can be difficult and tedious to select a goal and to annotate programs for input to a static checker.” (http://www.sciencedirect.com/science/article/pii/S1571066104002567)


\section{Motivation}
more practical view? Intro? Background?



\chapter{Background}

\section{Categorization of existing stuff}
% TODO: define contract somewhere

\cite{arlt2014gradual}
GraVy:
metric of progress of the verification process
and allows the verification engineer to focus on the remaining statements.
Gradual verification is not a new static verification technique. It is an extension
that can be applied to any existing static verification techniques to provide
additional information to the verification engineer. Thus, issues, such as handling
of loops or aliasing are not addressed in this paper. These are problems
related to sound verification, but gradual verification is about how to make the
use of such verification more traceable and quantifiable

\cite{nelson2004extended} ESC/Java
Software development and maintenance are costly endeavors.
The cost can be reduced if more software defects are
detected earlier in the development cycle. This paper introduces
the Extended Static Checker for Java (ESC/Java),
an experimental compile-time program checker that finds
common programming errors. The checker is powered by
verification-condition generation and automatic theorem proving
techniques. It provides programmers with a simple
annotation language with which programmer design decisions
can be expressed formally. ESC/Java examines the
annotated software and warns of inconsistencies between the
design decisions recorded in the annotations and the actual
code, and also warns of potential runtime errors in the code.
This paper gives an overview of the checker architecture and
annotation language and describes our experience applying
the checker to tens of thousands of lines of Java programs.

\cite{jacobs2001logic} JML => static verification

\cite{cheon2002runtime} JML => RAC

\cite{the-spec-programming-system-an-overview} Spec\#

\cite{a-statically-verifiable-programming-model-for-concurrent-object-oriented-programs} Spec\# extension (concurrent OO)

\cite{meyer2002design} Design-by-Contract
then also: Eiffel by Bertrand Meyer 

\cite{embedded-contract-languages} Code Contracts! Combines runtime and static checking

\cite{crocker2004safe} “verified design-by-contract”

\cite{ChristakisMuellerWuestholz16}
= static verification plus directed dynamic verification
In this paper, we present a technique to complement partial
verification results by automatic test case generation. In
contrast to existing work, our technique supports the common
case that the verification results are based on unsound
assumptions. We annotate programs to reflect which executions
have been verified, and under which assumptions.
These annotations are then used to guide dynamic symbolic
execution toward unverified program executions. Our main
technical contribution is a code instrumentation that causes
dynamic symbolic execution to abort tests that lead to verified
executions, to prune parts of the search space, and to
prioritize tests that cover more properties that are not fully
verified.

\section{Hoare Logic}
...for static semantics

\cite{hoare1969axiomatic}

\section{Related Work}
\subsection{Abstracting Gradual Typing}
\cite{siek2006gradual}
Gradual Typing for Functional Languages

apply their gradual typing approach to other areas

\cite{siek2015refined}
Refined criteria for gradual typing
gradual guarantee:
     The gradual guarantee says that if a gradually typed program is
     well typed, then removing type annotations always produces a program that is still well typed.
     Further, if a gradually typed program evaluates to a value, then removing type annotations
     always produces a program that evaluates to an equivalent value.

\cite{garcia2016abstracting}
AGT
In this paper, we propose a new formal foundation for gradual
typing, drawing on principles from abstract interpretation to
give gradual types a semantics in terms of preexisting static types.
Abstracting Gradual Typing (AGT for short) yields a formal account
of consistency—one of the cornerstones of the gradual typing
approach—that subsumes existing notions of consistency, which
were developed through intuition and ad hoc reasoning.

\cite{garcia2015deriving}
Abstracting Gradual Typing (AGT) is an approach to systematically
deriving gradual counterparts to static type disciplines (Garcia
et al. 2016). The approach consists of defining the semantics of
gradual types by interpreting them as sets of static types, and then
defining an optimal abstraction back to gradual types. These operations
are used to lift the static discipline to the gradual setting. The
runtime semantics of the gradual language then arises as reductions
on gradual typing derivations.
To demonstrate the flexibility of AGT, we gradualize
a prototypical security-typed language
with respect to only security labels rather than entire types, yielding
a type system that ranges gradually from simply-typed to securely typed.
We establish noninterference for our gradual language using Zdancewic’s logical relation proof method.
Whereas prior work presents gradual security cast languages,
which require explicit security casts, this work yields the first gradual
security source language, which requires no explicit casts.

prior to AGT
\cite{wolff2011gradual}
the language extends the notion of gradual typing to account for typestate: gradual typestate
checking seamlessly combines static and dynamic checking by automatically
inserting runtime checks into programs.

\cite{banados2014theory}
 develop a theory of gradual effect checking, which
 makes it possible to incrementally annotate and statically check
 effects, while still rejecting statically inconsistent programs. We
 extend the generic type-and-effect framework of Marino and Millstein
 with a notion of unknown effects, which turns out to be significantly
 more subtle than unknown types in traditional gradual
 typing. We appeal to abstract interpretation to develop and validate
 the concepts of gradual effect checking.

\cite{toro2015customizable}
Grad Effects in Scala, benchmarks on runtime impact!

\subsection{Implicit Dynamic Frames}

Race-free Assertion language! => static verification tool able to reason soundly about concurrent programs

% separating conjuction (= Multiplicative conjunction ⊗, lollipop, ...), access is resource, cannot duplicate access, ...
% TODO: explain Frame Problem
% translation of separating conjuction to regular conjunction? would simplify later reasoning A LOT

\cite{smans2009implicit}
IDF


\cite{leino2009verification}
Chalice, a verification methodology based on implicit dynamic frames

Chalice’s verification methodology centers around permissions and permission transfer. In particular, a memory location may be accessed by a thread only if that thread has permission to do so. Proper use of permissions allows Chalice to deduce upper bounds on the set of locations modifiable by a method and guarantees the absence of data races for concurrent programs. The lecture notes informally explain how Chalice works through various examples.

also: Viper (Verification Infrastructure for Permission-based Reasoning; is a suite of tools developed at ETH Zurich, providing an architecture on which new verification tools and prototypes can be developed simply and quickly.) has Chalice as front-end

\cite{summers2013formal}
In this paper, we provide both an isorecursive and an equirecursive formal
semantics for recursive definitions in the context of Chalice

\cite{parkinson2011relationship}
VERY IMPORTANT: chapter 2.2

Finally, we show that we can encode the separation
logic fragment of our logic into the implicit dynamic frames fragment, preserving
semantics. For the connectives typically supported by tools, this shows that separation
logic can be faithfully encoded in a first-order automatic verification tool (Chalice).

Although IDF was partially inspired by separation logic, there are many differences
between SL and IDF that make understanding their relationship difficult. SL does not
allow expressions that refer to the heap, while IDF does. SL is defined on partial heaps,
while IDF is defined using total heaps and permission masks. The semantics of IDF are only defined by its translation to first-order verification conditions, while SL has a direct
Kripke semantics for its assertions.

\subsubsection{Self-Framing}



%STRUCTURE:
% - intruduce static sample language (interesting for IDF, blabla, ..., but also general enough to transfer ideas)
% - gradualize sample language without focus on impl. details (assume NPC/undec. sat, impl, ... to stay general), i.e. focus on principal correctness        (undecidable in general => SMT solvers)
% - implement this very language and show effects of precision, ...


\chapter{Gradualization of a Statically Verified Language}
% TODO: at some point define what statically verified (verification as part of static semantics, no compilation without verification success) vs dynamically verified (no static measures, only (implicit) runtime cecks) means!

%% why start with static language
As illustrated earlier %MAKE SURE!
gradual verification can be seen as an extension of both static and dynamic verification.
% Both can be seen as the endpoints of the continuum...?
Yet, our approach of “gradualization” formalizes the introduction of the dynamic aspect into a fully static system.
Thus, this %TODO: work, section, chapter?
uses a statically verified language as starting point.
Later %TODO: ref
we will show how a programming language without static verification can be approached.

%% structure of this chapter
% TODO

\section{A Generic Statically Verified Language (\gsvl)}
\label{sec:a-statically-verified}
\input{text/SEC-a-statically-verified}



\section{Deriving a Gradually Verified Language}
% TODO: overall approach
% reference implementation chapter, explain difference (here: general, there: making use of specifics, optimality, minimal runtime overhead (0 if static, ...) ...)

\subsection{Gradual Formulas}
\begin{align*}
&\grad{\phi} \quad ::= \quad \phi ~|~ \withqm{\phi}
\end{align*}
% lifting predicates, lifting functions, lifting function composition (sound but not nec. optimal), ...

\subsection{Abstracting Static Semantics}
% non-deterministic static hoare rules make “quality of lifting” reasoning hard! if even {a}...{true} is valid statically, how to express/measure “badness” of emitting {a}...{?}
% Hoare rules (in a sound language) GUARANTEE that intermediate formulas hold at runtime 
% non-deterministic gradual hoare rules do NOT guarantee that!

% take burdon of chosing “good” intermediate formulas off verifier:
\begin{verbatim}
{ ? }
x := 2;
{ ? } // too weak, not optimal
assert (x = 3);
\end{verbatim}
\begin{verbatim}
{ ? }
assert (x != 0);
{ (x = 42) } // too strong, “somewhat unsound!!!” (no guarantee of holding at runtime, assuming previsous formula held)

// BUT supported by instantiation!!!

{ (x = 42) }
assert (x != 0);
{ (x = 42) }
\end{verbatim}
% instead, make rules deterministic and inherently sound
% => they might still not be optimal (we will define measure), but at least verifier is not to blame
% => about non-optimality formalism is to blame, not some inference mechanism (conflict of interest! formulas as strong as possible, verifier as “good”/successful as possible)
% => whether “working” intermediate formula exists is generally not even decidable! (already follows from satisfiability itself not being decidable...)

% wlp not an option since not well-defined for some rules:
\begin{displaymath}
\predicate{wlp}(\text{“\sVarAssign{x}{a.f}”}, \phiAcc{b}{f}) =
\begin{cases}
\phiCons {\phiAcc{b}{f}} {\phiAcc{a}{f}}\\
\phiCons {\phiAcc{b}{f}} {\phiEq{a}{b}}
\end{cases}
\end{displaymath}

\begin{align*}
\funHoare_s : \setFormulaB \rightharpoonup \setFormulaB\\
\funHoare_s = \funHoareC_s \circ \funHoareB_s \circ \funHoareA_s\\
\funHoare_s(\pb{\phi}) = \funHoareC_s(\pb{\phi}) \quad\text{ if $\funHoareApred(s) \wedge \pb{\phi} \implies \funHoareBimp(s)$} \\
\funHoareA_s : \setFormulaB \rightharpoonup \setFormulaB\\
\funHoareA_s(\pb{\phi}) = \pb{\phi} \quad\text{ if $\funHoareApred(s)$} \\
\funHoareB_s : \setFormulaB \rightharpoonup \setFormulaB\\
\funHoareB_s(\pb{\phi}) = \pb{\phi} \quad\text{ if $\pb{\phi} \implies \funHoareBimp(s)$} \\
\funHoareC_s : \setFormulaB \rightarrow \setFormulaB\\
\end{align*}

% example of determinified Hoare rule

% lifting... challenges

\subsection{Abstracting Dynamic Semantics}
% thing with HSec
% Tapp usw...

% THIS IS WHERE THE SIMPLIFICATION AND ALL ITS REASONING COMES IN!

\chapter{Implementation / Case Study / ...}

\section{Language}
%% more about our language
We now intrude a very simple Java-like statically verified language “\svl” that uses Chalice/Eiffel/Spec\# %???
sub-syntax to express method contracts.

% more about simplicity
% - decidable satisfiability & implication of formulas (will later investigate how to extend... ) % TODO
% - exactly one method arg, return type
% - not only decidable, but even polytime static semantics - entire area of research to extend boundaries there

\subsection{Syntax}
\label{sec:syntax}
\input{text/SEC-syntax}

\subsection{Formulas}
Not all syntactically correct formulas are useful in a static verification system.
We will introduce two subsets \setFormulaA and \setFormulaB ...

% def of footprint
% def of frm, sfrm
% implication
% variants of *

\subsection{Static Semantics}% requires sfrm
\label{sec:static-semantics}
\input{text/SEC-static-semantics}

\subsection{Well-Formedness}
\label{sec:well-formedness}
\input{text/SEC-well-formedness}

\subsection{Dynamic Semantics}
\label{ssec:dynamic-semantics}
\input{text/SSEC-dynamic-semantics}

\subsection{Soundness}

\section{Prepare Hoare Rules}

\subsection{Deterministic Functions}
\begin{displaymath}
\funHoareApred(s) =
\begin{cases}

\end{cases}
\end{displaymath}

\section{Gradualize Hoare Rules}

\subsection{Gradualize Functions}
% IDF stuff will probably only show up here!

\section{Enhancing an Unverified Language}


\chapter{Evaluation/Analysis}
> E:
with gradual typestates the same problem happened: as soon as the potential for unknown annotations was accepted, there was a “baseline cost” just to maintain the necessary infrastructure.
With simple gradual types, it’s almost nothing. With gradual effects, we’ve shown that it can boil down to very little (a thread-local variable with little overhead, see OOPSLA’15). 

% relationship LC and verification! which rules are derived by which, correspondence table


\chapter{Conclusion}
Recap, remind reader what big picture was.
Briefly outline your thesis, motivation, problem, and proposed solution.

\section{Limitations}

\section{Future Work}


\chapter{Appendix}


\chapter{UNSORTED}

\section{HoareMotivEx}
\label{sec:hoaremotivex}
\input{text/SEC-hoaremotivex}

\section{MotivationExamples}
\label{sec:motivationexamples}
\input{text/SEC-motivationexamples}
