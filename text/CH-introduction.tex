%% program verification
Program verification aims to check a computer program against its specification.
Automated methods require this specification to be formalized, e.g. using annotations in the source code.
Common examples are method contracts, loop invariants and assertions.

%% static vs dynamic
Approaches to check whether program behavior complies with given annotations can be divided into two categories:
\begin{description}
    \item[Static verification]~\\
        The program is not executed. 
        Instead \textbf{formal methods} (like Hoare logic or separation logic) are used, trying to derive a proof for given assertions.
        
        \textbf{Drawbacks}\\
        The syntax available for static verification is naturally limited by the underlying formal logic.
        Complex properties might thus not be expressible, resulting in inability to prove subsequent goals.
        Furthermore, the logic itself might fail proving certain goals due to code complexity and undecidability in general.
        Using static verification usually requires rigorous annotation of the entire source code, as otherwise there might be too little information to find a proof.
        While fully annotating own code can be tedious (there are supporting tools), using unannotated libraries can become a problem:
        Even if it is possible annotate the API afterwards, lacking the source code the verifier is unable to prove those annotations.
        In case the annotation are wrong this results in inconsistent proofs.
        
    \item[Dynamic verification]~\\
        The specification is turned into \textbf{runtime checks}, making sure that the program adheres to its specification during execution.
        Violations cause a runtime exception to be thrown, effectively preventing the program from entering a state that contradicts its specification.
        Note that in practice this approach is often combined with control flow based testing techniques to detect misbehavior as early as possible.
        
        \textbf{Drawbacks}\\
        Violations are only detected at runtime, with the risk of going unnoticed before software is released.
        To minimize this risk, testing methods are required, i.e. more time has to be spent after compilation.
        The usage of runtime checks naturally imposes a runtime overhead which is not always acceptable.
\end{description}

The goal of this work is to formalize “gradual verification”, an approach that seamlessly combines static and dynamic verification in order to weaken or even avoid above drawbacks.
The resulting system provides a continuum between traditional static and dynamic verification, meaning that both extremes are compatible with, but only special cases of the gradual verification system.
Section \ref{sec:motivationexamples} gives example scenarios of both static and dynamic verification suffering from their drawbacks, illustrating how gradual verification could avoid them.
% Programmers

Our approach is based on recent formalizations regarding gradual typing, using the concept of abstract interpretation to define a gradual system in terms of a static one (this process is called “gradualization”).
Gradual typing emerged from very similar drawbacks of static and dynamic type systems.
This is no surprise from a theoretical perspective as type systems are a special case of program verification. 
These similarities motivated our idea of reinterpreting and adapting the gradual typing approach to the verification setting.

Chapter \ref{sec:categorization-of-existing} introduces the concepts motivating and driving our approach.
Furthermore it categorizes existing work that goes in a similar direction, pointing out how it differs from our work.
In chapter \ref{ch:gradualization-of-a} we describe our approach of gradualization in a generic way, meant to be used as a manual or template for designing gradual verification systems.
We follow that manual in form of case study in chapter \ref{ch:case-study--implicit}, applying the approach to a statically verified language that uses implicit dynamic frames in order to enable safe static reasoning about shared mutable state.

% TODO: remaining chapters

\begin{comment}
~\\ % more detail???


Most modern programming languages use static methods to some degree, ruling out at least some types of runtime failure.
%% static typing
Static typing disciplines are among the most common representatives, guaranteeing type safety at compile time, obviating the need for dynamic checks.
Yet, the rigidity and limitations of static type systems resulted in the introduction of dynamic aspects into the otherwise static system:
Casts (e.g. as implemented in C\# or Java) overrule purely static reasoning, allowing the static type system to treat an expression as if it had the claimed type (usually a subtype) instead of the deduced one.
At this location, a runtime check is introduced, resulting in a cast exception should the programmer's claim turn out wrong.
Note that such deviations from a purely static type system (one where there is no need for runtime checks) do not affect type safety:
It is still guaranteed that execution does not enter an inconsistent state by simply interrupting execution whenever a runtime type check fails.

Note that casts are necessary only because of a typical drawback of static systems, namely the limitation of the underlying logic.
More sophisticated type systems (e.g. the one in Haskell) might have been able to deduce the claimed type in the first place.

%% dynamic typing
%At the other end of the spectrum are dynamically typed languages.
%In scenarios where the limitations of a static type system would clutter up the source code, they allow expressing the same logic with less %syntactic overhead, but at the cost of less static guarantees and early bug detection.

%% static verification
In contrast, general purpose static verification techniques are not common amongst popular programming languages.
Note that such languages are usually driven by cost-benefit and usability considerations, meaning that static verification is apparently not yet in a stage where its cost clearly outweighs its benefits.
\end{comment}

\begin{comment}
%% static verification
% example?

% research Eiffel!
% Design-by-Contract!!! Eiffel!
% D even has both

% this is more of a consequence of the “deep roots” of dynamic verification!!!
%But even preconditions at expression level are implemented as runtime checks, reflected all the way down at instruction architecture level.
%Examples:
%\begin{description}
%    \item[Division by zero]~\\
%    Integer division performs a dynamic check...
%    
%\end{description}

- 
What is the thesis about?
Why is it relevant or important?
What are the issues or problems?
What is the proposed solution or approach?
What can one expect in the rest of the thesis?

“Static verification checks that properties are always true, but it can be difficult and tedious to select a goal and to annotate programs for input to a static checker.” (http://www.sciencedirect.com/science/article/pii/S1571066104002567)
\end{comment}